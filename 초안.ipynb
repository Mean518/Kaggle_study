{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Conv2D, Dropout, MaxPool2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rho</th>\n",
       "      <th>650_src</th>\n",
       "      <th>660_src</th>\n",
       "      <th>670_src</th>\n",
       "      <th>680_src</th>\n",
       "      <th>690_src</th>\n",
       "      <th>700_src</th>\n",
       "      <th>710_src</th>\n",
       "      <th>720_src</th>\n",
       "      <th>730_src</th>\n",
       "      <th>...</th>\n",
       "      <th>940_dst</th>\n",
       "      <th>950_dst</th>\n",
       "      <th>960_dst</th>\n",
       "      <th>970_dst</th>\n",
       "      <th>980_dst</th>\n",
       "      <th>990_dst</th>\n",
       "      <th>hhb</th>\n",
       "      <th>hbo2</th>\n",
       "      <th>ca</th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.37950</td>\n",
       "      <td>0.42993</td>\n",
       "      <td>0.52076</td>\n",
       "      <td>0.57166</td>\n",
       "      <td>0.67818</td>\n",
       "      <td>0.75476</td>\n",
       "      <td>0.83580</td>\n",
       "      <td>0.93623</td>\n",
       "      <td>0.96333</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067504e-18</td>\n",
       "      <td>5.998949e-18</td>\n",
       "      <td>4.378513e-17</td>\n",
       "      <td>5.59</td>\n",
       "      <td>4.32</td>\n",
       "      <td>8.92</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01813</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.00321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343132e-08</td>\n",
       "      <td>6.112685e-09</td>\n",
       "      <td>2.130547e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.710091e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.83</td>\n",
       "      <td>7.25</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03289</td>\n",
       "      <td>0.02416</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.05843</td>\n",
       "      <td>0.09015</td>\n",
       "      <td>0.14944</td>\n",
       "      <td>0.18578</td>\n",
       "      <td>0.25584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.329725e-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.64</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.27503</td>\n",
       "      <td>0.31281</td>\n",
       "      <td>0.32898</td>\n",
       "      <td>0.41041</td>\n",
       "      <td>0.46587</td>\n",
       "      <td>0.52769</td>\n",
       "      <td>0.64369</td>\n",
       "      <td>0.73562</td>\n",
       "      <td>0.79865</td>\n",
       "      <td>...</td>\n",
       "      <td>2.245998e-10</td>\n",
       "      <td>1.299511e-10</td>\n",
       "      <td>7.782625e-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.088921e-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.67</td>\n",
       "      <td>4.01</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1.01521</td>\n",
       "      <td>1.00872</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>0.98874</td>\n",
       "      <td>1.01773</td>\n",
       "      <td>1.01632</td>\n",
       "      <td>1.00009</td>\n",
       "      <td>0.98217</td>\n",
       "      <td>1.01564</td>\n",
       "      <td>...</td>\n",
       "      <td>1.457955e-13</td>\n",
       "      <td>8.769053e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.330237e-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.97</td>\n",
       "      <td>4.41</td>\n",
       "      <td>10.78</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>15</td>\n",
       "      <td>0.23929</td>\n",
       "      <td>0.30265</td>\n",
       "      <td>0.39929</td>\n",
       "      <td>0.51000</td>\n",
       "      <td>0.64072</td>\n",
       "      <td>0.77328</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.95891</td>\n",
       "      <td>0.98998</td>\n",
       "      <td>...</td>\n",
       "      <td>6.788642e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.516467e-16</td>\n",
       "      <td>9.690979e-16</td>\n",
       "      <td>1.391635e-15</td>\n",
       "      <td>5.460702e-14</td>\n",
       "      <td>12.68</td>\n",
       "      <td>4.11</td>\n",
       "      <td>12.31</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>20</td>\n",
       "      <td>0.02583</td>\n",
       "      <td>0.00946</td>\n",
       "      <td>0.03650</td>\n",
       "      <td>0.01380</td>\n",
       "      <td>0.04093</td>\n",
       "      <td>0.04363</td>\n",
       "      <td>0.03260</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.04608</td>\n",
       "      <td>...</td>\n",
       "      <td>1.814274e-16</td>\n",
       "      <td>1.117148e-16</td>\n",
       "      <td>7.352416e-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.825347e-16</td>\n",
       "      <td>4.226436e-15</td>\n",
       "      <td>8.46</td>\n",
       "      <td>4.11</td>\n",
       "      <td>10.46</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10</td>\n",
       "      <td>0.57589</td>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.70571</td>\n",
       "      <td>0.77248</td>\n",
       "      <td>0.85402</td>\n",
       "      <td>0.92796</td>\n",
       "      <td>0.97691</td>\n",
       "      <td>0.98933</td>\n",
       "      <td>1.00493</td>\n",
       "      <td>...</td>\n",
       "      <td>4.828451e-11</td>\n",
       "      <td>3.110419e-11</td>\n",
       "      <td>8.119095e-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.504115e-10</td>\n",
       "      <td>4.003657e-10</td>\n",
       "      <td>9.84</td>\n",
       "      <td>3.20</td>\n",
       "      <td>10.45</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>15</td>\n",
       "      <td>1.01477</td>\n",
       "      <td>1.01504</td>\n",
       "      <td>0.99125</td>\n",
       "      <td>0.98747</td>\n",
       "      <td>1.00717</td>\n",
       "      <td>1.01434</td>\n",
       "      <td>0.99529</td>\n",
       "      <td>1.01322</td>\n",
       "      <td>1.00486</td>\n",
       "      <td>...</td>\n",
       "      <td>3.279271e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.475946e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.818857e-12</td>\n",
       "      <td>1.408742e-11</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.06</td>\n",
       "      <td>11.28</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10</td>\n",
       "      <td>0.24452</td>\n",
       "      <td>0.28182</td>\n",
       "      <td>0.36493</td>\n",
       "      <td>0.42131</td>\n",
       "      <td>0.50305</td>\n",
       "      <td>0.61418</td>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.78836</td>\n",
       "      <td>0.85105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.499067e-12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.219509e-11</td>\n",
       "      <td>3.259396e-12</td>\n",
       "      <td>3.830300e-11</td>\n",
       "      <td>9.35</td>\n",
       "      <td>4.34</td>\n",
       "      <td>9.73</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rho  650_src  660_src  670_src  680_src  690_src  700_src  710_src  \\\n",
       "id                                                                         \n",
       "0      25  0.37950  0.42993  0.52076  0.57166  0.67818  0.75476  0.83580   \n",
       "1      10  0.00000  0.00000  0.01813  0.00000  0.00000  0.01974  0.00321   \n",
       "2      25  0.00000  0.03289  0.02416  0.03610  0.05843  0.09015  0.14944   \n",
       "3      10  0.27503  0.31281  0.32898  0.41041  0.46587  0.52769  0.64369   \n",
       "4      15  1.01521  1.00872  0.98930  0.98874  1.01773  1.01632  1.00009   \n",
       "...   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "9995   15  0.23929  0.30265  0.39929  0.51000  0.64072  0.77328  0.86722   \n",
       "9996   20  0.02583  0.00946  0.03650  0.01380  0.04093  0.04363  0.03260   \n",
       "9997   10  0.57589  0.62976  0.70571  0.77248  0.85402  0.92796  0.97691   \n",
       "9998   15  1.01477  1.01504  0.99125  0.98747  1.00717  1.01434  0.99529   \n",
       "9999   10  0.24452  0.28182  0.36493  0.42131  0.50305  0.61418  0.70350   \n",
       "\n",
       "      720_src  730_src  ...       940_dst       950_dst       960_dst  \\\n",
       "id                      ...                                             \n",
       "0     0.93623  0.96333  ...           NaN  0.000000e+00           NaN   \n",
       "1     0.00000  0.00000  ...  1.343132e-08  6.112685e-09  2.130547e-09   \n",
       "2     0.18578  0.25584  ...  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3     0.73562  0.79865  ...  2.245998e-10  1.299511e-10  7.782625e-11   \n",
       "4     0.98217  1.01564  ...  1.457955e-13  8.769053e-14           NaN   \n",
       "...       ...      ...  ...           ...           ...           ...   \n",
       "9995  0.95891  0.98998  ...  6.788642e-16  0.000000e+00  5.516467e-16   \n",
       "9996  0.05282  0.04608  ...  1.814274e-16  1.117148e-16  7.352416e-17   \n",
       "9997  0.98933  1.00493  ...  4.828451e-11  3.110419e-11  8.119095e-12   \n",
       "9998  1.01322  1.00486  ...  3.279271e-13  0.000000e+00  4.475946e-14   \n",
       "9999  0.78836  0.85105  ...  2.499067e-12  0.000000e+00  0.000000e+00   \n",
       "\n",
       "           970_dst       980_dst       990_dst    hhb  hbo2     ca    na  \n",
       "id                                                                        \n",
       "0     1.067504e-18  5.998949e-18  4.378513e-17   5.59  4.32   8.92  4.29  \n",
       "1              NaN  9.710091e-09           NaN   0.00  2.83   7.25  4.64  \n",
       "2     0.000000e+00  1.329725e-18           NaN  10.64  3.00   8.40  5.16  \n",
       "3              NaN  4.088921e-10           NaN   5.67  4.01   5.05  4.35  \n",
       "4     1.330237e-13           NaN           NaN  11.97  4.41  10.78  2.42  \n",
       "...            ...           ...           ...    ...   ...    ...   ...  \n",
       "9995  9.690979e-16  1.391635e-15  5.460702e-14  12.68  4.11  12.31  0.10  \n",
       "9996           NaN  5.825347e-16  4.226436e-15   8.46  4.11  10.46  3.12  \n",
       "9997           NaN  1.504115e-10  4.003657e-10   9.84  3.20  10.45  2.06  \n",
       "9998           NaN  2.818857e-12  1.408742e-11   6.38  4.06  11.28  4.03  \n",
       "9999  1.219509e-11  3.259396e-12  3.830300e-11   9.35  4.34   9.73  3.54  \n",
       "\n",
       "[10000 rows x 75 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.interpolate()\n",
    "test = test.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(train.mean())\n",
    "test = test.fillna(train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 75)\n",
      "(10000, 71)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "x_predict = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[:,:71]\n",
    "y = train[:,71:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x) \n",
    "x = scaler.transform(x)\n",
    "x_predict = scaler.transform(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 71)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 52)                3744      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 228)               12084     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 356)               81524     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 356)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 250)               89250     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 164)               41164     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 164)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                10560     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 238,586\n",
      "Trainable params: 238,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(52, input_dim=(71))) \n",
    "model.add(Dense(228))\n",
    "model.add(Dense(356))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(250))\n",
    "model.add(Dense(164))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(4, activation='relu')) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8000/8000 [==============================] - 0s 24us/step - loss: 4.6125 - mae: 4.6125\n",
      "Epoch 2/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 3.8370 - mae: 3.8370\n",
      "Epoch 3/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 3.3756 - mae: 3.3756\n",
      "Epoch 4/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 2.9636 - mae: 2.9636\n",
      "Epoch 5/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 2.3815 - mae: 2.3815\n",
      "Epoch 6/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 2.0980 - mae: 2.0980\n",
      "Epoch 7/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.9512 - mae: 1.9512\n",
      "Epoch 8/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.8796 - mae: 1.8796\n",
      "Epoch 9/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.8372 - mae: 1.8372\n",
      "Epoch 10/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.8175 - mae: 1.8175\n",
      "Epoch 11/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.8014 - mae: 1.8014\n",
      "Epoch 12/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7987 - mae: 1.7987\n",
      "Epoch 13/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7904 - mae: 1.7904\n",
      "Epoch 14/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7912 - mae: 1.7912\n",
      "Epoch 15/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7896 - mae: 1.7896\n",
      "Epoch 16/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7859 - mae: 1.7859\n",
      "Epoch 17/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7903 - mae: 1.7903\n",
      "Epoch 18/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7822 - mae: 1.7822\n",
      "Epoch 19/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7902 - mae: 1.7902\n",
      "Epoch 20/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7767 - mae: 1.7767\n",
      "Epoch 21/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7779 - mae: 1.7779\n",
      "Epoch 22/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7883 - mae: 1.7883\n",
      "Epoch 23/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7930 - mae: 1.7930\n",
      "Epoch 24/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7739 - mae: 1.7739\n",
      "Epoch 25/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7687 - mae: 1.7687\n",
      "Epoch 26/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7640 - mae: 1.7640\n",
      "Epoch 27/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7831 - mae: 1.7831\n",
      "Epoch 28/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7723 - mae: 1.7723\n",
      "Epoch 29/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7713 - mae: 1.7713\n",
      "Epoch 30/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7687 - mae: 1.7687\n",
      "Epoch 31/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7678 - mae: 1.7678\n",
      "Epoch 32/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7650 - mae: 1.7650\n",
      "Epoch 33/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7727 - mae: 1.7727\n",
      "Epoch 34/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7638 - mae: 1.7638\n",
      "Epoch 35/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7639 - mae: 1.7639\n",
      "Epoch 36/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7626 - mae: 1.7626\n",
      "Epoch 37/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7620 - mae: 1.7620\n",
      "Epoch 38/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7625 - mae: 1.7625\n",
      "Epoch 39/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7655 - mae: 1.7655\n",
      "Epoch 40/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7726 - mae: 1.7726\n",
      "Epoch 41/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7677 - mae: 1.7677\n",
      "Epoch 42/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7535 - mae: 1.7535\n",
      "Epoch 43/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7603 - mae: 1.7603\n",
      "Epoch 44/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7565 - mae: 1.7565\n",
      "Epoch 45/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7501 - mae: 1.7501\n",
      "Epoch 46/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7564 - mae: 1.7564\n",
      "Epoch 47/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7631 - mae: 1.7631\n",
      "Epoch 48/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7662 - mae: 1.7662\n",
      "Epoch 49/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7536 - mae: 1.7536\n",
      "Epoch 50/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7552 - mae: 1.7552\n",
      "Epoch 51/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7578 - mae: 1.7578\n",
      "Epoch 52/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7570 - mae: 1.7570\n",
      "Epoch 53/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7552 - mae: 1.7552\n",
      "Epoch 54/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7578 - mae: 1.7578\n",
      "Epoch 55/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7604 - mae: 1.7604\n",
      "Epoch 56/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7578 - mae: 1.7578\n",
      "Epoch 57/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7601 - mae: 1.7601\n",
      "Epoch 58/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7515 - mae: 1.7515\n",
      "Epoch 59/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7534 - mae: 1.7534\n",
      "Epoch 60/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7537 - mae: 1.7537\n",
      "Epoch 61/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7539 - mae: 1.7539\n",
      "Epoch 62/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7551 - mae: 1.7551\n",
      "Epoch 63/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7558 - mae: 1.7558\n",
      "Epoch 64/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7545 - mae: 1.7545\n",
      "Epoch 65/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7614 - mae: 1.7614\n",
      "Epoch 66/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7605 - mae: 1.7605\n",
      "Epoch 67/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7551 - mae: 1.7551\n",
      "Epoch 68/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7493 - mae: 1.7493\n",
      "Epoch 69/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7542 - mae: 1.7542\n",
      "Epoch 70/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7526 - mae: 1.7526\n",
      "Epoch 71/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7552 - mae: 1.7552\n",
      "Epoch 72/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7545 - mae: 1.7545\n",
      "Epoch 73/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7462 - mae: 1.7462\n",
      "Epoch 74/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7566 - mae: 1.7566\n",
      "Epoch 75/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7486 - mae: 1.7486\n",
      "Epoch 76/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7449 - mae: 1.7449\n",
      "Epoch 77/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7448 - mae: 1.7448\n",
      "Epoch 78/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7463 - mae: 1.7463\n",
      "Epoch 79/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7504 - mae: 1.7504\n",
      "Epoch 80/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7460 - mae: 1.7460\n",
      "Epoch 81/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7513 - mae: 1.7513\n",
      "Epoch 82/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7448 - mae: 1.7448\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7545 - mae: 1.7545\n",
      "Epoch 84/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7503 - mae: 1.7503\n",
      "Epoch 85/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7461 - mae: 1.7461\n",
      "Epoch 86/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7456 - mae: 1.7456\n",
      "Epoch 87/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7473 - mae: 1.7473\n",
      "Epoch 88/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7478 - mae: 1.7478\n",
      "Epoch 89/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7454 - mae: 1.7454\n",
      "Epoch 90/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7431 - mae: 1.7431\n",
      "Epoch 91/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7436 - mae: 1.7436\n",
      "Epoch 92/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7424 - mae: 1.7424\n",
      "Epoch 93/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7500 - mae: 1.7500\n",
      "Epoch 94/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7496 - mae: 1.7496\n",
      "Epoch 95/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7481 - mae: 1.7481\n",
      "Epoch 96/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7539 - mae: 1.7539\n",
      "Epoch 97/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7497 - mae: 1.7497\n",
      "Epoch 98/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7481 - mae: 1.7481\n",
      "Epoch 99/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7451 - mae: 1.7451\n",
      "Epoch 100/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7440 - mae: 1.7440\n",
      "Epoch 101/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7463 - mae: 1.7463\n",
      "Epoch 102/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7432 - mae: 1.7432\n",
      "Epoch 103/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7413 - mae: 1.7413\n",
      "Epoch 104/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7387 - mae: 1.7387\n",
      "Epoch 105/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7434 - mae: 1.7434\n",
      "Epoch 106/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7488 - mae: 1.7488\n",
      "Epoch 107/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7431 - mae: 1.7431\n",
      "Epoch 108/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7459 - mae: 1.7459\n",
      "Epoch 109/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7445 - mae: 1.7445\n",
      "Epoch 110/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7418 - mae: 1.7418\n",
      "Epoch 111/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7388 - mae: 1.7388\n",
      "Epoch 112/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7380 - mae: 1.7380\n",
      "Epoch 113/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7438 - mae: 1.7438\n",
      "Epoch 114/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7409 - mae: 1.7409\n",
      "Epoch 115/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7401 - mae: 1.7401\n",
      "Epoch 116/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7373 - mae: 1.7373\n",
      "Epoch 117/150\n",
      "8000/8000 [==============================] - 0s 5us/step - loss: 1.7386 - mae: 1.7386\n",
      "Epoch 118/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7365 - mae: 1.7365\n",
      "Epoch 119/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7417 - mae: 1.7417\n",
      "Epoch 120/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7468 - mae: 1.7468\n",
      "Epoch 121/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7392 - mae: 1.7392\n",
      "Epoch 122/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7439 - mae: 1.7439\n",
      "Epoch 123/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7426 - mae: 1.7426\n",
      "Epoch 124/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7387 - mae: 1.7387\n",
      "Epoch 125/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7370 - mae: 1.7370\n",
      "Epoch 126/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7412 - mae: 1.7412\n",
      "Epoch 127/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7384 - mae: 1.7384\n",
      "Epoch 128/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7376 - mae: 1.7376\n",
      "Epoch 129/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7373 - mae: 1.7373\n",
      "Epoch 130/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7429 - mae: 1.7429\n",
      "Epoch 131/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7377 - mae: 1.7377\n",
      "Epoch 132/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7388 - mae: 1.7388\n",
      "Epoch 133/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7386 - mae: 1.7386\n",
      "Epoch 134/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7420 - mae: 1.7420\n",
      "Epoch 135/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7353 - mae: 1.7353\n",
      "Epoch 136/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7342 - mae: 1.7342\n",
      "Epoch 137/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7378 - mae: 1.7378\n",
      "Epoch 138/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7357 - mae: 1.7357\n",
      "Epoch 139/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7361 - mae: 1.7361\n",
      "Epoch 140/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7349 - mae: 1.7349\n",
      "Epoch 141/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7381 - mae: 1.7381\n",
      "Epoch 142/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7387 - mae: 1.7387\n",
      "Epoch 143/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7393 - mae: 1.7393\n",
      "Epoch 144/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7312 - mae: 1.7312\n",
      "Epoch 145/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7306 - mae: 1.7306\n",
      "Epoch 146/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7310 - mae: 1.7310\n",
      "Epoch 147/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7316 - mae: 1.7316\n",
      "Epoch 148/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7341 - mae: 1.7341\n",
      "Epoch 149/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7353 - mae: 1.7353\n",
      "Epoch 150/150\n",
      "8000/8000 [==============================] - 0s 4us/step - loss: 1.7303 - mae: 1.7303\n",
      "1.7441143267513803\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer='adam', metrics=['mae']) \n",
    "model.fit(x_train,y_train, epochs=150, batch_size=1001)\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_absolute_error(y_pred, y_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.utils.testing import all_estimators  # sklearn 0.20.1에서만 돌아감요\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (8000, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5a89d1461cfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallAlgorithms\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'의 mae = '\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \"\"\"\n\u001b[0;32m    445\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64, y_numeric=True,\n\u001b[1;32m--> 446\u001b[1;33m                          ensure_min_samples=2)\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    759\u001b[0m                         dtype=None)\n\u001b[0;32m    760\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (8000, 4)"
     ]
    }
   ],
   "source": [
    "allAlgorithms = all_estimators(type_filter='regressor')\n",
    "\n",
    "for (name, algorithm) in allAlgorithms :\n",
    "    model = algorithm()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(name, '의 mae = ',  mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhb</th>\n",
       "      <th>hbo2</th>\n",
       "      <th>ca</th>\n",
       "      <th>na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hhb  hbo2  ca  na\n",
       "id                      \n",
       "10000    0     0   0   0\n",
       "10001    0     0   0   0\n",
       "10002    0     0   0   0\n",
       "10003    0     0   0   0\n",
       "10004    0     0   0   0\n",
       "...    ...   ...  ..  ..\n",
       "19995    0     0   0   0\n",
       "19996    0     0   0   0\n",
       "19997    0     0   0   0\n",
       "19998    0     0   0   0\n",
       "19999    0     0   0   0\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission\n",
    "# 와우 4개를 맞추는거네...?\n",
    "# 심지어 결측치도 있음\n",
    "# 일단 어떤 데이터인지 보고 결측치 처리하는거 고려해봐야해 왜냐면 test셋에도 결측치가 있기 때문임\n",
    "# 지금으로써는 결측치 많은 칼럼은 아예 없애버리고 싶음 왜냐면 이미 칼럼이 너무 많아\n",
    "# 대회는 import가 전부다 ^^@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
